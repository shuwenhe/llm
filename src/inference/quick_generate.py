"""å¿«é€Ÿæ–‡æœ¬ç”Ÿæˆæµ‹è¯•è„šæœ¬"""
import torch
from model import GPT
from config import ModelConfig
from data import load_tokenizer


def quick_test():
    """å¿«é€Ÿæµ‹è¯•ä¸åŒå‚æ•°çš„ç”Ÿæˆæ•ˆæœ"""
    # é…ç½®
    checkpoint_path = "checkpoints/best_model.pt"
    device = torch.device("cuda" if torch.cuda.is_available() else 
                         "mps" if torch.backends.mps.is_available() else "cpu")
    
    print(f"ğŸš€ å¿«é€Ÿç”Ÿæˆæµ‹è¯•")
    print(f"è®¾å¤‡: {device}")
    print("="*60)
    
    # åŠ è½½æ¨¡å‹
    checkpoint = torch.load(checkpoint_path, map_location=device)
    model_config = ModelConfig(**checkpoint['model_config'])
    model = GPT(model_config)
    model.load_state_dict(checkpoint['model'])
    model.eval()
    model.to(device)
    
    tokenizer = load_tokenizer()
    
    # æµ‹è¯•æç¤ºè¯
    test_prompts = [
        "Once upon a time",
        "The meaning of life is",
        "In a world where",
    ]
    
    # æµ‹è¯•å‚æ•°ç»„åˆ
    test_configs = [
        {'name': 'ä¿å®ˆæ¨¡å¼', 'temp': 0.7, 'top_k': 50},
        {'name': 'å¹³è¡¡æ¨¡å¼', 'temp': 0.8, 'top_k': 200},
        {'name': 'åˆ›æ„æ¨¡å¼', 'temp': 1.0, 'top_k': 300},
    ]
    
    for prompt in test_prompts:
        print(f"\n{'='*60}")
        print(f"ğŸ“ æç¤ºè¯: \"{prompt}\"")
        print(f"{'='*60}")
        
        for cfg in test_configs:
            print(f"\nğŸ”§ {cfg['name']} (temp={cfg['temp']}, top_k={cfg['top_k']})")
            print("-"*60)
            
            # ç¼–ç 
            tokens = tokenizer.encode(prompt, return_tensors='pt').to(device)
            
            # ç”Ÿæˆ
            with torch.no_grad():
                generated_tokens = model.generate(
                    tokens,
                    max_new_tokens=150,
                    temperature=cfg['temp'],
                    top_k=cfg['top_k']
                )
            
            # è§£ç 
            generated_text = tokenizer.decode(generated_tokens[0].tolist())
            print(generated_text)
    
    print("\n" + "="*60)
    print("âœ… æµ‹è¯•å®Œæˆï¼é€‰æ‹©æ•ˆæœæœ€å¥½çš„å‚æ•°åœ¨ generate.py ä¸­ä½¿ç”¨")


if __name__ == "__main__":
    quick_test()
