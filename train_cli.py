#!/usr/bin/env python3
"""OpenAIé£æ ¼çš„å·¥ä¸šçº§è®­ç»ƒå‘½ä»¤ - æ”¯æŒé…ç½®ã€æ—¥å¿—ã€ç›‘æ§"""
import json
import argparse
import subprocess
import sys
from pathlib import Path
from datetime import datetime
from typing import Optional


class TrainingConfig:
    """è®­ç»ƒé…ç½®ç®¡ç†"""
    
    PRESETS = {
        # å¿«é€ŸéªŒè¯
        "quick": {
            "batch_size": 2,
            "epochs": 1,
            "learning_rate": 1e-4,
            "save_every_epoch": True,
            "keep_last_n": 1,
        },
        # æ ‡å‡†è®­ç»ƒ
        "standard": {
            "batch_size": 4,
            "epochs": 3,
            "learning_rate": 1e-4,
            "save_every_epoch": True,
            "keep_last_n": 3,
        },
        # é•¿æœŸè®­ç»ƒ
        "extended": {
            "batch_size": 8,
            "epochs": 10,
            "learning_rate": 5e-5,
            "save_every_epoch": True,
            "keep_last_n": 5,
        },
        # é«˜ç²¾åº¦è®­ç»ƒ
        "precision": {
            "batch_size": 16,
            "epochs": 20,
            "learning_rate": 1e-5,
            "save_every_epoch": True,
            "keep_last_n": 10,
        },
    }
    
    @classmethod
    def from_preset(cls, preset_name: str) -> dict:
        """ä»é¢„è®¾åŠ è½½é…ç½®"""
        if preset_name not in cls.PRESETS:
            raise ValueError(f"æœªçŸ¥çš„é¢„è®¾: {preset_name}. å¯ç”¨: {list(cls.PRESETS.keys())}")
        return cls.PRESETS[preset_name]
    
    @classmethod
    def from_file(cls, config_file: str) -> dict:
        """ä»é…ç½®æ–‡ä»¶åŠ è½½"""
        with open(config_file) as f:
            return json.load(f)
    
    @classmethod
    def save_config(cls, config: dict, output_file: str):
        """ä¿å­˜é…ç½®"""
        with open(output_file, 'w') as f:
            json.dump(config, f, indent=2)
        print(f"âœ“ é…ç½®å·²ä¿å­˜: {output_file}")


class TrainingLogger:
    """è®­ç»ƒæ—¥å¿—ç®¡ç†"""
    
    def __init__(self, log_dir: str = "logs"):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.log_file = self.log_dir / f"training_{timestamp}.log"
        self.config_file = self.log_dir / f"config_{timestamp}.json"
    
    def log(self, message: str):
        """è®°å½•æ—¥å¿—"""
        with open(self.log_file, 'a') as f:
            f.write(f"[{datetime.now().isoformat()}] {message}\n")
        print(message)
    
    def save_config(self, config: dict):
        """ä¿å­˜é…ç½®"""
        with open(self.config_file, 'w') as f:
            json.dump(config, f, indent=2)
    
    def get_summary(self) -> dict:
        """è·å–æ—¥å¿—æ‘˜è¦"""
        return {
            'log_file': str(self.log_file),
            'config_file': str(self.config_file),
            'timestamp': datetime.now().isoformat(),
        }


def build_training_command(config: dict, data_file: Optional[str] = None) -> list:
    """æ„å»ºè®­ç»ƒå‘½ä»¤"""
    cmd = [
        "./venv/bin/python",
        "train_chinese.py",
    ]
    
    # æ·»åŠ å‚æ•°
    if data_file:
        cmd.extend(["--data-file", data_file])
    
    cmd.extend([
        "--batch-size", str(config.get("batch_size", 4)),
        "--epochs", str(config.get("epochs", 3)),
        "--learning-rate", str(config.get("learning_rate", 1e-4)),
    ])
    
    if not config.get("save_every_epoch", True):
        cmd.append("--no-save-every-epoch")
    
    if "keep_last_n" in config:
        cmd.extend(["--keep-last-n", str(config["keep_last_n"])])
    
    return cmd


def main():
    parser = argparse.ArgumentParser(
        description="OpenAIé£æ ¼çš„å·¥ä¸šçº§è®­ç»ƒå‘½ä»¤",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å¿«é€ŸéªŒè¯
  python train_cli.py --preset quick

  # æ ‡å‡†è®­ç»ƒ
  python train_cli.py --preset standard --data-file data/zh_sample.txt

  # è‡ªå®šä¹‰è®­ç»ƒ
  python train_cli.py --batch-size 8 --epochs 5 --learning-rate 1e-5

  # ä»é…ç½®æ–‡ä»¶è®­ç»ƒ
  python train_cli.py --config config.json

  # åˆ—å‡ºå¯ç”¨é¢„è®¾
  python train_cli.py --list-presets
        """
    )
    
    # é¢„è®¾é€‰é¡¹
    preset_group = parser.add_argument_group("é¢„è®¾é…ç½®")
    preset_group.add_argument(
        "--preset",
        choices=list(TrainingConfig.PRESETS.keys()),
        help="ä½¿ç”¨é¢„è®¾é…ç½® (quick, standard, extended, precision)"
    )
    preset_group.add_argument(
        "--list-presets",
        action="store_true",
        help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨é¢„è®¾"
    )
    
    # é…ç½®é€‰é¡¹
    config_group = parser.add_argument_group("é…ç½®ç®¡ç†")
    config_group.add_argument(
        "--config",
        help="ä»JSONé…ç½®æ–‡ä»¶åŠ è½½"
    )
    config_group.add_argument(
        "--save-config",
        help="ä¿å­˜å½“å‰é…ç½®åˆ°æ–‡ä»¶"
    )
    
    # è®­ç»ƒå‚æ•°
    train_group = parser.add_argument_group("è®­ç»ƒå‚æ•°")
    train_group.add_argument(
        "--batch-size",
        type=int,
        help="æ‰¹æ¬¡å¤§å°"
    )
    train_group.add_argument(
        "--epochs",
        type=int,
        help="è®­ç»ƒè½®æ•°"
    )
    train_group.add_argument(
        "--learning-rate",
        type=float,
        help="å­¦ä¹ ç‡"
    )
    train_group.add_argument(
        "--data-file",
        help="è®­ç»ƒæ•°æ®æ–‡ä»¶"
    )
    train_group.add_argument(
        "--keep-last-n",
        type=int,
        help="ä¿ç•™æœ€è¿‘Nä¸ªæ£€æŸ¥ç‚¹"
    )
    train_group.add_argument(
        "--no-save-every-epoch",
        action="store_true",
        help="ä¸ä¿å­˜æ¯ä¸ªepochçš„æ£€æŸ¥ç‚¹"
    )
    
    # æ‰§è¡Œé€‰é¡¹
    exec_group = parser.add_argument_group("æ‰§è¡Œé€‰é¡¹")
    exec_group.add_argument(
        "--dry-run",
        action="store_true",
        help="æ‰“å°å‘½ä»¤ä½†ä¸æ‰§è¡Œ"
    )
    exec_group.add_argument(
        "--resume",
        action="store_true",
        help="ä»æœ€æ–°æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ"
    )
    exec_group.add_argument(
        "--no-log",
        action="store_true",
        help="ä¸è®°å½•æ—¥å¿—"
    )
    
    args = parser.parse_args()
    
    # åˆ—å‡ºé¢„è®¾
    if args.list_presets:
        print("\nğŸ“‹ å¯ç”¨çš„è®­ç»ƒé¢„è®¾:")
        print("=" * 80)
        for name, config in TrainingConfig.PRESETS.items():
            print(f"\n{name.upper()}")
            print(f"  æ‰¹æ¬¡å¤§å°: {config['batch_size']}")
            print(f"  è®­ç»ƒè½®æ•°: {config['epochs']}")
            print(f"  å­¦ä¹ ç‡: {config['learning_rate']}")
        print()
        return
    
    # åŠ è½½é…ç½®
    config = {}
    
    if args.config:
        config = TrainingConfig.from_file(args.config)
        print(f"âœ“ ä»é…ç½®æ–‡ä»¶åŠ è½½: {args.config}")
    elif args.preset:
        config = TrainingConfig.from_preset(args.preset)
        print(f"âœ“ ä½¿ç”¨é¢„è®¾: {args.preset}")
    else:
        config = TrainingConfig.from_preset("standard")
        print(f"âœ“ ä½¿ç”¨é»˜è®¤é¢„è®¾: standard")
    
    # è¦†ç›–å‘½ä»¤è¡Œå‚æ•°
    if args.batch_size:
        config["batch_size"] = args.batch_size
    if args.epochs:
        config["epochs"] = args.epochs
    if args.learning_rate:
        config["learning_rate"] = args.learning_rate
    if args.keep_last_n:
        config["keep_last_n"] = args.keep_last_n
    if args.no_save_every_epoch:
        config["save_every_epoch"] = False
    
    # æ·»åŠ resumeé€‰é¡¹
    if args.resume:
        config["resume"] = True
    
    # åˆå§‹åŒ–æ—¥å¿—
    logger = None
    if not args.no_log:
        logger = TrainingLogger()
        logger.save_config(config)
    
    # æ‰“å°é…ç½®
    print("\n" + "=" * 80)
    print("ğŸ“ è®­ç»ƒé…ç½®")
    print("=" * 80)
    for key, value in config.items():
        if key not in ["resume"]:
            print(f"  {key}: {value}")
    print("=" * 80 + "\n")
    
    # æ„å»ºå‘½ä»¤
    cmd = build_training_command(config, args.data_file)
    
    # æ·»åŠ resumeæ ‡å¿—
    if args.resume:
        cmd.append("--resume")
    
    if logger:
        logger.log(f"å‘½ä»¤: {' '.join(cmd)}")
    
    # æ‰“å°å‘½ä»¤
    print(f"ğŸ“ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}\n")
    
    if args.dry_run:
        print("âœ“ å¹²è¿è¡Œæ¨¡å¼ (ä¸æ‰§è¡Œ)")
        if logger:
            logger.log("å¹²è¿è¡Œæ¨¡å¼")
        return
    
    # æ‰§è¡Œè®­ç»ƒ
    try:
        if logger:
            logger.log("=" * 80)
            logger.log("å¼€å§‹è®­ç»ƒ")
            logger.log("=" * 80)
        
        result = subprocess.run(cmd, check=True)
        
        if logger:
            logger.log("=" * 80)
            logger.log("âœ“ è®­ç»ƒå®Œæˆ")
            logger.log(f"ğŸ“Š æ—¥å¿—: {logger.get_summary()['log_file']}")
            logger.log("=" * 80)
        
        sys.exit(result.returncode)
        
    except subprocess.CalledProcessError as e:
        if logger:
            logger.log(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        sys.exit(1)
    except KeyboardInterrupt:
        if logger:
            logger.log("âš ï¸  è®­ç»ƒè¢«ä¸­æ–­")
        print("\nâš ï¸  è®­ç»ƒè¢«ä¸­æ–­")
        sys.exit(130)


if __name__ == "__main__":
    main()
