# ğŸ“ è®­ç»ƒå’Œæ£€æŸ¥ç‚¹é€ŸæŸ¥å¡

## ğŸš€ æœ€å¿«å¼€å§‹ï¼ˆå¤åˆ¶ç²˜è´´ï¼‰

```bash
# å¿«é€ŸéªŒè¯
python train_cli.py --preset quick

# æ ‡å‡†è®­ç»ƒ
python train_cli.py --preset standard --data-file data/zh_sample.txt

# ä¸€é”®å¯åŠ¨è„šæœ¬
bash quick_start.sh standard data/zh_sample.txt
```

## ğŸ“Š 5ä¸ªæ ¸å¿ƒå‘½ä»¤

| åŠŸèƒ½ | å‘½ä»¤ | è¯´æ˜ |
|------|------|------|
| ğŸ“‹ æŸ¥çœ‹é¢„è®¾ | `python train_cli.py --list-presets` | åˆ—å‡º4ä¸ªé¢„è®¾é…ç½® |
| ğŸ§ª å¹²è¿è¡Œ | `python train_cli.py --preset quick --dry-run` | éªŒè¯å‘½ä»¤ä¸æ‰§è¡Œ |
| ğŸ“ å¼€å§‹è®­ç»ƒ | `python train_cli.py --preset standard` | æ‰§è¡Œæ ‡å‡†è®­ç»ƒ |
| ğŸ“ˆ æŸ¥çœ‹ç»“æœ | `python train_manager.py history` | è®­ç»ƒå†å²å’ŒæŸå¤±æ›²çº¿ |
| ğŸ”„ æ¢å¤è®­ç»ƒ | `python train_cli.py --resume --epochs 5` | ä»latest.ptæ¢å¤ |

## ğŸ† 4ä¸ªè®­ç»ƒé¢„è®¾

| é¢„è®¾ | å‘½ä»¤ | æ—¶é—´ | ç”¨é€” |
|------|------|------|------|
| QUICK | `--preset quick` | 1åˆ†é’Ÿ | éªŒè¯ç®¡é“ |
| STANDARD | `--preset standard` | 30åˆ†é’Ÿ | æ—¥å¸¸ä½¿ç”¨ |
| EXTENDED | `--preset extended` | 2å°æ—¶ | æ·±åº¦è®­ç»ƒ |
| PRECISION | `--preset precision` | 5å°æ—¶ | ç”Ÿäº§éƒ¨ç½² |

## ğŸ“ ä¸‰çº§æ£€æŸ¥ç‚¹é€ŸæŸ¥

| æ–‡ä»¶ | ç”¨é€” | ä½•æ—¶æ›´æ–° | ä½•æ—¶ä½¿ç”¨ |
|------|------|---------|--------|
| `model_epoch_*.pt` | è½®æ¬¡å†å² | æ¯è½®ä¿å­˜ | å¯¹æ¯”è½®æ¬¡è´¨é‡ |
| `best_model.pt` | æœ€ä¼˜æ¨¡å‹ | æŸå¤±æ”¹è¿›æ—¶ | ç”Ÿäº§éƒ¨ç½² |
| `latest.pt` | æœ€æ–°æ¨¡å‹ | æ¯è½®ä¿å­˜ | æ¢å¤è®­ç»ƒ |

## ğŸ¯ æ£€æŸ¥ç‚¹ç®¡ç†å‘½ä»¤

```bash
# åˆ—å‡ºæ‰€æœ‰æ£€æŸ¥ç‚¹
python train_manager.py list

# æŸ¥çœ‹è®­ç»ƒå†å²
python train_manager.py history

# å¯¹æ¯”ä¸¤ä¸ªæ¨¡å‹
python train_manager.py compare model1.pt model2.pt

# æ¸…ç†æ—§æ£€æŸ¥ç‚¹
python train_manager.py clean --keep 3
```

## ğŸ” å®æ—¶ç›‘æ§æ£€æŸ¥ç‚¹

### æ–¹å¼1: watchå‘½ä»¤ï¼ˆæœ€ç®€å•ï¼‰
```bash
watch -n 1 'ls -lh checkpoints/*.pt | tail -5'
```

### æ–¹å¼2: æŒç»­ç›‘æ§
```bash
while true; do
  clear
  echo "ğŸ“Š æ£€æŸ¥ç‚¹:" 
  ls -lh checkpoints/*.pt
  sleep 2
done
```

### æ–¹å¼3: ç›‘æ§è„šæœ¬
```bash
bash monitor_training.sh
```

## ğŸš€ ä½¿ç”¨æ£€æŸ¥ç‚¹

### ç”Ÿäº§éƒ¨ç½²
```bash
LLM_CHECKPOINT=checkpoints/best_model.pt make serve
```

### ç»§ç»­è®­ç»ƒï¼ˆå¿«é€Ÿï¼‰
```bash
python train_cli.py --resume --epochs 5
```

### ä»ç‰¹å®šè½®ç»§ç»­
```bash
python train_chinese.py --checkpoint checkpoints/model_epoch_2.pt --epochs 3
```

### åœ¨æœ€ä¼˜åŸºç¡€ä¸Šå¾®è°ƒ
```bash
python train_cli.py --preset extended \
  --checkpoint checkpoints/best_model.pt \
  --learning-rate 5e-5 \
  --epochs 10
```

## ğŸ“š æ–‡æ¡£å¯¼èˆª

| æ–‡æ¡£ | å†…å®¹ | ä½•æ—¶çœ‹ |
|------|------|--------|
| [QUICK_REFERENCE.md](QUICK_REFERENCE.md) | å¿«é€ŸæŒ‡å— | ç¬¬1æ¬¡ä½¿ç”¨ |
| [TRAINING_README.md](TRAINING_README.md) | å®Œæ•´åŠŸèƒ½è¯´æ˜ | äº†è§£å…¨è²Œ |
| [docs/checkpoint_system.md](docs/checkpoint_system.md) | æ£€æŸ¥ç‚¹è¯¦è§£ | ç†è§£åŸç† |
| [docs/training_visualization.md](docs/training_visualization.md) | ç›‘æ§æŒ‡å— | å®æ—¶ç›‘æ§ |
| [docs/commands_reference.md](docs/commands_reference.md) | å‘½ä»¤å‚è€ƒ | æŸ¥æ‰¾å‘½ä»¤ |

## ğŸ’¡ å¸¸è§åœºæ™¯

### åœºæ™¯1: æˆ‘æƒ³å¿«é€ŸéªŒè¯
```bash
python train_cli.py --preset quick
# âœ… 1åˆ†é’Ÿå®Œæˆï¼Œç”Ÿæˆå®Œæ•´çš„3çº§æ£€æŸ¥ç‚¹
```

### åœºæ™¯2: æ ‡å‡†è®­ç»ƒ
```bash
bash quick_start.sh standard data/zh_sample.txt
# âœ… 30åˆ†é’Ÿï¼Œå®Œæ•´UIï¼Œæœ€åæ˜¾ç¤ºæ‰€æœ‰æ£€æŸ¥ç‚¹
```

### åœºæ™¯3: è®­ç»ƒä¸­æ–­äº†ï¼Œè¦æ¢å¤
```bash
python train_cli.py --resume --epochs 10
# âœ… ä»latest.ptæ¢å¤ï¼ŒåŒ…å«ä¼˜åŒ–å™¨çŠ¶æ€
```

### åœºæ™¯4: ç”¨æœ€å¥½çš„æ¨¡å‹éƒ¨ç½²
```bash
LLM_CHECKPOINT=checkpoints/best_model.pt make serve
# âœ… è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ¨¡å‹å¯åŠ¨æœåŠ¡
```

### åœºæ™¯5: å¯¹æ¯”ä¸åŒè½®çš„æ¨¡å‹
```bash
python train_manager.py compare \
  checkpoints/model_epoch_1.pt \
  checkpoints/best_model.pt
# âœ… æ˜¾ç¤ºæ€§èƒ½å¯¹æ¯”
```

## ğŸ”§ å‚æ•°é€ŸæŸ¥

### è®­ç»ƒå‚æ•°
```bash
python train_cli.py \
  --preset standard           # ä½¿ç”¨é¢„è®¾
  --batch-size 8             # æ”¹æ‰¹æ¬¡å¤§å°
  --epochs 5                 # æ”¹è½®æ•°
  --learning-rate 5e-5       # æ”¹å­¦ä¹ ç‡
  --data-file data/zh_wiki.txt # æ•°æ®æ–‡ä»¶
  --keep-last-n 5            # ä¿ç•™5ä¸ªepoch
```

### ç‰¹æ®Šé€‰é¡¹
```bash
--dry-run                    # åªæ˜¾ç¤ºå‘½ä»¤ä¸æ‰§è¡Œ
--resume                     # ä»latestæ¢å¤
--no-save-every-epoch        # ä¸ä¿å­˜epochæ£€æŸ¥ç‚¹
--no-log                     # ä¸è®°å½•æ—¥å¿—
```

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡ï¼ˆ15.6GB VRAMï¼‰

| é¢„è®¾ | æ‰¹æ¬¡ | è½®æ•° | æ—¶é—´ | æ˜¾å­˜å ç”¨ |
|------|------|------|------|---------|
| QUICK | 2 | 1 | 1åˆ†é’Ÿ | 3GB |
| STANDARD | 4 | 3 | 30åˆ†é’Ÿ | 5GB |
| EXTENDED | 8 | 10 | 2å°æ—¶ | 8GB |
| PRECISION | 16 | 20 | 5å°æ—¶ | 12GB |

## âœ… æ£€æŸ¥æ¸…å•

### è®­ç»ƒå‰
- [ ] `python train_cli.py --list-presets` æŸ¥çœ‹é¢„è®¾
- [ ] `python train_cli.py --preset quick --dry-run` éªŒè¯å‘½ä»¤
- [ ] ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´ï¼ˆ~3GBï¼‰
- [ ] æ£€æŸ¥GPUæ˜¾å­˜è¶³å¤Ÿ

### è®­ç»ƒä¸­
- [ ] ç”¨ `watch` å‘½ä»¤ç›‘æ§æ£€æŸ¥ç‚¹ç”Ÿæˆ
- [ ] æˆ–åœ¨å¦ä¸€ä¸ªç»ˆç«¯çœ‹æ—¥å¿— `tail -f logs/*.log`
- [ ] å¦‚éœ€ä¸­æ–­ï¼ŒCtrl+C å³å¯ï¼ˆlatest.ptä¿å­˜äº†å®Œæ•´çŠ¶æ€ï¼‰

### è®­ç»ƒå
- [ ] `python train_manager.py list` æŸ¥çœ‹æ‰€æœ‰æ£€æŸ¥ç‚¹
- [ ] `python train_manager.py history` æŸ¥çœ‹è®­ç»ƒæ›²çº¿
- [ ] ç¡®è®¤ `best_model.pt` æ˜¯æœ€ä¼˜æ¨¡å‹
- [ ] å¤‡ä»½é‡è¦çš„æ¨¡å‹ `cp best_model.pt backup/`

### éƒ¨ç½²æ—¶
- [ ] ä½¿ç”¨ `best_model.pt` è€Œä¸æ˜¯ `latest.pt`
- [ ] å‘½ä»¤: `LLM_CHECKPOINT=checkpoints/best_model.pt make serve`
- [ ] æµ‹è¯•æ¨¡å‹æ¨ç†æ•ˆæœ

## ğŸš¨ æ•…éšœæ’æŸ¥

### çœ‹ä¸åˆ°æ£€æŸ¥ç‚¹ä¿å­˜ä¿¡æ¯
```bash
# æŸ¥çœ‹æ—¥å¿—è€Œä¸æ˜¯ç»ˆç«¯è¾“å‡º
python train_cli.py --preset quick 2>&1 | tee train.log
tail -f train.log | grep -E "(ä¿å­˜|æ£€æŸ¥ç‚¹)"
```

### æ˜¾å­˜ä¸è¶³
```bash
# ä½¿ç”¨quické¢„è®¾æˆ–é™ä½batch_size
python train_cli.py --preset quick
python train_cli.py --batch-size 1 --epochs 1
```

### æ£€æŸ¥ç‚¹æ–‡ä»¶å¾ˆå¤§
```bash
# ä¸ä¿å­˜epochæ£€æŸ¥ç‚¹ï¼Œåªä¿ç•™bestå’Œlatest
python train_cli.py --preset standard --no-save-every-epoch
```

### ç£ç›˜ç©ºé—´æ»¡
```bash
# æ¸…ç†æ—§æ£€æŸ¥ç‚¹
python train_manager.py clean --keep 2
```

## ğŸ‰ é¢„æœŸç»“æœ

è®­ç»ƒ3è½®åï¼š

```
checkpoints/
â”œâ”€â”€ model_epoch_1.pt (487MB)
â”œâ”€â”€ model_epoch_2.pt (487MB) â­ æœ€ä¼˜
â”œâ”€â”€ model_epoch_3.pt (487MB)
â”œâ”€â”€ best_model.pt (487MB) ğŸ† æŒ‡å‘epoch2
â”œâ”€â”€ latest.pt (487MB) ğŸ“Œ æŒ‡å‘epoch3
â”œâ”€â”€ model.pt (487MB) ğŸ“ ä¸»æ£€æŸ¥ç‚¹
â””â”€â”€ training_history.json

$ python train_manager.py history
ğŸ“Š æœ€ä½³éªŒè¯æŸå¤±: 3.8012 (Epoch 2)

$ LLM_CHECKPOINT=checkpoints/best_model.pt make serve
âœ“ ä½¿ç”¨æœ€ä¼˜æ¨¡å‹å¯åŠ¨æœåŠ¡
```

## ğŸ”— å¿«é€Ÿé“¾æ¥

- ğŸ“– [å®Œæ•´æŒ‡å—](openai_training_guide.md)
- ğŸ“– [å‘½ä»¤å‚è€ƒ](docs/commands_reference.md)
- ğŸ“– [æ£€æŸ¥ç‚¹ç³»ç»Ÿ](docs/checkpoint_system.md)
- ğŸ“– [ç›‘æ§å¯è§†åŒ–](docs/training_visualization.md)
- ğŸ“– [æ›´æ–°è¯¦æƒ…](CHECKPOINT_UPDATE.md)

---

**è®°ä½**: 
- ğŸ† ç”Ÿäº§éƒ¨ç½²ç”¨ `best_model.pt`
- ğŸ“Œ æ¢å¤è®­ç»ƒç”¨ `latest.pt`
- ğŸ“¦ å†å²ä¿å­˜åœ¨ `model_epoch_*.pt`
- ğŸ“ˆ å®Œæ•´æ•°æ®åœ¨ `training_history.json`

**ä»»ä½•é—®é¢˜**: æŸ¥çœ‹å¯¹åº”çš„æ–‡æ¡£å³å¯æ‰¾åˆ°ç­”æ¡ˆï¼
