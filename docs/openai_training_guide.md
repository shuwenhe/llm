# OpenAIé£æ ¼çš„å·¥ä¸šçº§è®­ç»ƒå‘½ä»¤

## ğŸ¯ æ¦‚è¿°

è¿™æ˜¯ä¸€å¥—ç¬¦åˆOpenAIæ ‡å‡†çš„å·¥ä¸šçº§è®­ç»ƒç³»ç»Ÿï¼Œæ”¯æŒï¼š
- âœ… é¢„è®¾é…ç½®ï¼ˆå¿«é€Ÿã€æ ‡å‡†ã€é«˜ç²¾åº¦ï¼‰
- âœ… é…ç½®æ–‡ä»¶ç®¡ç†
- âœ… å®Œæ•´æ—¥å¿—è®°å½•
- âœ… å¹²è¿è¡Œæ¨¡å¼
- âœ… æ–­ç‚¹ç»­è®­
- âœ… å‘½ä»¤è¡Œçµæ´»æ€§

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ä½¿ç”¨é¢„è®¾è®­ç»ƒ

```bash
# å¿«é€ŸéªŒè¯ï¼ˆ1è½®ï¼ŒéªŒè¯ç®¡é“ï¼‰
python train_cli.py --preset quick

# æ ‡å‡†è®­ç»ƒï¼ˆ3è½®ï¼Œé»˜è®¤é…ç½®ï¼‰
python train_cli.py --preset standard --data-file data/zh_sample.txt

# é•¿æœŸè®­ç»ƒï¼ˆ10è½®ï¼‰
python train_cli.py --preset extended --data-file data/zh_sample.txt

# é«˜ç²¾åº¦è®­ç»ƒï¼ˆ20è½®ï¼Œä½å­¦ä¹ ç‡ï¼‰
python train_cli.py --preset precision --data-file data/zh_sample.txt
```

### 2. åˆ—å‡ºå¯ç”¨é¢„è®¾

```bash
python train_cli.py --list-presets
```

è¾“å‡ºï¼š
```
ğŸ“‹ å¯ç”¨çš„è®­ç»ƒé¢„è®¾:
================================================================================

QUICK
  æ‰¹æ¬¡å¤§å°: 2
  è®­ç»ƒè½®æ•°: 1
  å­¦ä¹ ç‡: 0.0001

STANDARD
  æ‰¹æ¬¡å¤§å°: 4
  è®­ç»ƒè½®æ•°: 3
  å­¦ä¹ ç‡: 0.0001

EXTENDED
  æ‰¹æ¬¡å¤§å°: 8
  è®­ç»ƒè½®æ•°: 10
  å­¦ä¹ ç‡: 5e-05

PRECISION
  æ‰¹æ¬¡å¤§å°: 16
  è®­ç»ƒè½®æ•°: 20
  å­¦ä¹ ç‡: 1e-05
```

## ğŸ“‹ é…ç½®ç®¡ç†

### ä»é…ç½®æ–‡ä»¶åŠ è½½

```bash
# ä½¿ç”¨é¢„è®¾é…ç½®æ–‡ä»¶
python train_cli.py --config config/training_standard.json

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
python train_cli.py --config my_config.json --data-file data/zh_wiki.txt
```

### ä¿å­˜å½“å‰é…ç½®

```bash
# ä¿å­˜é¢„è®¾é…ç½®
python train_cli.py --preset precision --save-config my_training.json

# æŸ¥çœ‹ä¿å­˜çš„é…ç½®
cat my_training.json
```

### é…ç½®æ–‡ä»¶æ ¼å¼

```json
{
  "batch_size": 4,
  "epochs": 3,
  "learning_rate": 1e-4,
  "save_every_epoch": true,
  "keep_last_n": 3
}
```

## âš™ï¸ è‡ªå®šä¹‰è®­ç»ƒ

### è¦†ç›–é¢„è®¾å‚æ•°

```bash
# ä»standardé¢„è®¾å¼€å§‹ï¼Œä½†æ”¹ä¸º10è½®
python train_cli.py --preset standard --epochs 10

# ç»„åˆå¤šä¸ªå‚æ•°
python train_cli.py --preset standard \
  --batch-size 8 \
  --epochs 5 \
  --learning-rate 5e-5 \
  --keep-last-n 5
```

### å®Œæ•´å‚æ•°åˆ—è¡¨

```bash
python train_cli.py \
  --batch-size 4          # æ‰¹æ¬¡å¤§å°
  --epochs 3              # è®­ç»ƒè½®æ•°
  --learning-rate 1e-4    # å­¦ä¹ ç‡
  --data-file data.txt    # æ•°æ®æ–‡ä»¶
  --keep-last-n 3         # ä¿ç•™æ£€æŸ¥ç‚¹æ•°
  --no-save-every-epoch   # ä¸ä¿å­˜epochæ£€æŸ¥ç‚¹
  --resume                # ä»latest.ptæ¢å¤
  --dry-run               # æ‰“å°ä½†ä¸æ‰§è¡Œ
  --no-log                # ä¸è®°å½•æ—¥å¿—
```

## ğŸ§ª å¹²è¿è¡Œæ¨¡å¼

åœ¨å®é™…æ‰§è¡Œå‰æµ‹è¯•å‘½ä»¤ï¼š

```bash
# æ£€æŸ¥å¿«é€Ÿè®­ç»ƒçš„å‘½ä»¤
python train_cli.py --preset quick --dry-run

# æ£€æŸ¥è‡ªå®šä¹‰å‚æ•°çš„å‘½ä»¤
python train_cli.py --batch-size 16 --epochs 20 --dry-run
```

è¾“å‡ºï¼š
```
âœ“ ä½¿ç”¨é¢„è®¾: quick

================================================================================
ğŸ“ è®­ç»ƒé…ç½®
================================================================================
  batch_size: 2
  epochs: 1
  learning_rate: 0.0001
  save_every_epoch: True
  keep_last_n: 1
================================================================================

ğŸ“ æ‰§è¡Œå‘½ä»¤: ./venv/bin/python train_chinese.py --batch-size 2 --epochs 1 ...
âœ“ å¹²è¿è¡Œæ¨¡å¼ (ä¸æ‰§è¡Œ)
```

## ğŸ“Š æ—¥å¿—è®°å½•

è®­ç»ƒè‡ªåŠ¨ç”Ÿæˆæ—¥å¿—ï¼š

```
logs/
â”œâ”€â”€ training_20260228_173000.log    # è®­ç»ƒæ—¥å¿—
â””â”€â”€ config_20260228_173000.json     # è®­ç»ƒé…ç½®
```

æŸ¥çœ‹æ—¥å¿—ï¼š
```bash
# æŸ¥çœ‹æœ€æ–°æ—¥å¿—
tail -f logs/training_*.log

# ç»Ÿè®¡è®­ç»ƒç»“æœ
grep "æœ€ä½³æŸå¤±" logs/training_*.log
```

## ğŸ”„ æ–­ç‚¹ç»­è®­

ä»ä¸­æ–­å¤„æ¢å¤ï¼š

```bash
# ç»§ç»­ä¹‹å‰çš„è®­ç»ƒ
python train_cli.py --preset standard --resume

# ç»§ç»­å¹¶æ‰©å±•è½®æ•°
python train_cli.py --preset extended --resume --data-file data/zh_sample.txt
```

## ğŸ“ é«˜çº§ç”¨æ³•

### æ¯”è¾ƒä¸åŒé…ç½®

```bash
# å¿«é€Ÿvsæ ‡å‡†
python train_cli.py --preset quick --dry-run
python train_cli.py --preset standard --dry-run

# ä¸åŒå­¦ä¹ ç‡
python train_cli.py --learning-rate 1e-4 --dry-run
python train_cli.py --learning-rate 5e-5 --dry-run
```

### æ‰¹é‡è®­ç»ƒ

```bash
#!/bin/bash
# é¡ºåºè¿è¡Œå¤šä¸ªè®­ç»ƒ

echo "å¿«é€ŸéªŒè¯..."
python train_cli.py --preset quick

echo "æ ‡å‡†è®­ç»ƒ..."
python train_cli.py --preset standard --data-file data/zh_sample.txt

echo "é«˜ç²¾åº¦è®­ç»ƒ..."
python train_cli.py --preset precision --data-file data/zh_sample.txt
```

### è°ƒåº¦è®­ç»ƒ

```bash
# åœ¨åå°è¿è¡Œ
nohup python train_cli.py --preset precision --data-file data/zh_wiki.txt > training.log 2>&1 &

# å®šæ—¶è®­ç»ƒï¼ˆæ¯æ™š11ç‚¹ï¼‰
0 23 * * * cd /home/shuwen/llm && python train_cli.py --preset extended --data-file data/zh_wiki.txt
```

## ğŸ“ˆ é¢„è®¾è¯¦è§£

### QUICKï¼ˆå¿«é€ŸéªŒè¯ï¼‰
- ç”¨é€”ï¼šéªŒè¯ç®¡é“ã€å¿«é€Ÿæµ‹è¯•
- æ‰¹æ¬¡ï¼š2ï¼ˆèŠ‚çœå†…å­˜ï¼‰
- è½®æ•°ï¼š1ï¼ˆå¿«é€Ÿå®Œæˆï¼‰
- å­¦ä¹ ç‡ï¼š1e-4ï¼ˆæ ‡å‡†ï¼‰
- æ—¶é—´ï¼š~1åˆ†é’Ÿ

### STANDARDï¼ˆæ ‡å‡†è®­ç»ƒï¼‰
- ç”¨é€”ï¼šæ—¥å¸¸è®­ç»ƒã€æ¨¡å‹å¾®è°ƒ
- æ‰¹æ¬¡ï¼š4ï¼ˆå¹³è¡¡æ˜¾å­˜å’Œè´¨é‡ï¼‰
- è½®æ•°ï¼š3ï¼ˆåŸºæœ¬æ”¶æ•›ï¼‰
- å­¦ä¹ ç‡ï¼š1e-4ï¼ˆæ ‡å‡†ï¼‰
- æ—¶é—´ï¼š~30åˆ†é’Ÿ

### EXTENDEDï¼ˆé•¿æœŸè®­ç»ƒï¼‰
- ç”¨é€”ï¼šæ·±åº¦å¾®è°ƒã€å¤§æ•°æ®é›†
- æ‰¹æ¬¡ï¼š8ï¼ˆæ›´å¤§æ‰¹æ¬¡ï¼‰
- è½®æ•°ï¼š10ï¼ˆå……åˆ†è®­ç»ƒï¼‰
- å­¦ä¹ ç‡ï¼š5e-5ï¼ˆé™ä½å­¦ä¹ ç‡ï¼‰
- æ—¶é—´ï¼š~2å°æ—¶

### PRECISIONï¼ˆé«˜ç²¾åº¦è®­ç»ƒï¼‰
- ç”¨é€”ï¼šç”Ÿäº§éƒ¨ç½²ã€æœ€ä¼˜æ¨¡å‹
- æ‰¹æ¬¡ï¼š16ï¼ˆå……åˆ†åˆ©ç”¨GPUï¼‰
- è½®æ•°ï¼š20ï¼ˆå……åˆ†æ”¶æ•›ï¼‰
- å­¦ä¹ ç‡ï¼š1e-5ï¼ˆå¾®è°ƒï¼‰
- æ—¶é—´ï¼š~5å°æ—¶

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. å¿«é€ŸéªŒè¯
```bash
python train_cli.py --preset quick
```

### 2. éªŒè¯æˆåŠŸåæ ‡å‡†è®­ç»ƒ
```bash
python train_cli.py --preset standard --data-file data/zh_sample.txt
```

### 3. æŸ¥çœ‹ç»“æœ
```bash
python train_manager.py list
python train_manager.py history
```

### 4. å¦‚éœ€æ”¹è¿›ï¼Œé«˜ç²¾åº¦è®­ç»ƒ
```bash
python train_cli.py --preset precision --resume --data-file data/zh_wiki.txt
```

### 5. éƒ¨ç½²æœ€ä½³æ¨¡å‹
```bash
LLM_CHECKPOINT=checkpoints/best_model.pt make serve
```

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜ï¼šGPUå†…å­˜ä¸è¶³
```bash
# ä½¿ç”¨quické¢„è®¾
python train_cli.py --preset quick

# æˆ–é™ä½batch_size
python train_cli.py --batch-size 2 --epochs 1
```

### é—®é¢˜ï¼šè®­ç»ƒä¸­æ–­
```bash
# æŸ¥çœ‹æ—¥å¿—
tail -f logs/training_*.log

# æ¢å¤è®­ç»ƒ
python train_cli.py --preset standard --resume
```

### é—®é¢˜ï¼šæƒ³è°ƒè¯•å‘½ä»¤
```bash
# ä½¿ç”¨å¹²è¿è¡Œæ¨¡å¼
python train_cli.py --preset precision --dry-run

# æŸ¥çœ‹å®Œæ•´å‘½ä»¤åä¿®æ”¹
```

## ğŸ“š ä¸Makefileé›†æˆ

åœ¨Makefileä¸­æ·»åŠ ï¼š

```makefile
train-openai:
	@python train_cli.py $(ARGS)

train-openai-quick:
	@python train_cli.py --preset quick

train-openai-standard:
	@python train_cli.py --preset standard --data-file $(DATA_FILE)

train-openai-precision:
	@python train_cli.py --preset precision --data-file $(DATA_FILE)
```

ä½¿ç”¨ï¼š
```bash
make train-openai --preset quick
make train-openai-standard DATA_FILE=data/zh_sample.txt
```
