# å·¥ä¸šçº§è®­ç»ƒè§£å†³æ–¹æ¡ˆ

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

### 1. å¤šçº§æ£€æŸ¥ç‚¹ç®¡ç†
- **æœ€ä½³æ¨¡å‹** (`best_model.pt`) - éªŒè¯æŸå¤±æœ€ä½çš„æ¨¡å‹
- **æœ€æ–°æ¨¡å‹** (`latest.pt`) - æ”¯æŒæ–­ç‚¹ç»­è®­
- **Epochæ£€æŸ¥ç‚¹** (`model_epoch_*.pt`) - æ¯è½®è‡ªåŠ¨ä¿å­˜
- **æ™ºèƒ½æ¸…ç†** - è‡ªåŠ¨ä¿ç•™æœ€è¿‘Nä¸ªæ£€æŸ¥ç‚¹

### 2. æ–­ç‚¹ç»­è®­
```bash
# ä»æœ€æ–°æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
python train_chinese.py --resume --epochs 5

# ä»æŒ‡å®šæ£€æŸ¥ç‚¹ç»§ç»­
python train_chinese.py --checkpoint checkpoints/model_epoch_3.pt --epochs 5
```

### 3. è®­ç»ƒå†å²è¿½è¸ª
```bash
# æŸ¥çœ‹æ‰€æœ‰æ£€æŸ¥ç‚¹
python train_manager.py list

# æŸ¥çœ‹è®­ç»ƒå†å²æ›²çº¿
python train_manager.py history

# æ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹
python train_manager.py compare checkpoints/best_model.pt checkpoints/latest.pt
```

## ğŸ“‹ ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€è®­ç»ƒ
```bash
# ä½¿ç”¨ç¤ºä¾‹æ•°æ®è®­ç»ƒ3è½®
python train_chinese.py --epochs 3 --batch-size 4

# ä½¿ç”¨çœŸå®æ•°æ®é›†
python train_chinese.py --data-file data/zh_sample.txt --epochs 5 --batch-size 8
```

### ç”Ÿæˆçš„æ–‡ä»¶ç»“æ„
```
checkpoints/
â”œâ”€â”€ best_model.pt           # ğŸ† æœ€ä½³æ¨¡å‹ï¼ˆéªŒè¯æŸå¤±æœ€ä½ï¼‰
â”œâ”€â”€ latest.pt               # ğŸ“Œ æœ€æ–°æ¨¡å‹ï¼ˆç”¨äºæ–­ç‚¹ç»­è®­ï¼‰
â”œâ”€â”€ model_epoch_1.pt        # ğŸ“¦ ç¬¬1è½®æ£€æŸ¥ç‚¹
â”œâ”€â”€ model_epoch_2.pt        # ğŸ“¦ ç¬¬2è½®æ£€æŸ¥ç‚¹
â”œâ”€â”€ model_epoch_3.pt        # ğŸ“¦ ç¬¬3è½®æ£€æŸ¥ç‚¹
â”œâ”€â”€ model.pt                # ğŸ“„ å‘åå…¼å®¹çš„ä¸»æ£€æŸ¥ç‚¹
â””â”€â”€ training_history.json   # ğŸ“ˆ è®­ç»ƒå†å²æ•°æ®
```

### é«˜çº§è®­ç»ƒé…ç½®
```bash
# ä¿ç•™æœ€è¿‘5ä¸ªepochæ£€æŸ¥ç‚¹
python train_chinese.py --epochs 10 --keep-last-n 5

# ä¸ä¿å­˜æ¯ä¸ªepochï¼ˆä»…bestå’Œlatestï¼‰
python train_chinese.py --epochs 5 --no-save-every-epoch

# è‡ªå®šä¹‰å­¦ä¹ ç‡
python train_chinese.py --epochs 3 --learning-rate 5e-5
```

## ğŸ”§ è®­ç»ƒç®¡ç†å·¥å…·

### æŸ¥çœ‹æ£€æŸ¥ç‚¹åˆ—è¡¨
```bash
python train_manager.py list
```
è¾“å‡ºç¤ºä¾‹ï¼š
```
æ–‡ä»¶                           Epoch    éªŒè¯æŸå¤±      å¤§å°(MB)   ä¿®æ”¹æ—¶é—´
--------------------------------------------------------------------------------
ğŸ† best_model.pt              2        1.2345       536.23     2026-02-28 17:30:15
ğŸ“Œ latest.pt                  3        1.3456       536.23     2026-02-28 17:45:20
ğŸ“¦ model_epoch_1.pt           0        1.5678       536.23     2026-02-28 17:10:00
ğŸ“¦ model_epoch_2.pt           1        1.2345       536.23     2026-02-28 17:25:10
ğŸ“¦ model_epoch_3.pt           2        1.3456       536.23     2026-02-28 17:40:15
```

### æŸ¥çœ‹è®­ç»ƒå†å²
```bash
python train_manager.py history
```
è¾“å‡ºç¤ºä¾‹ï¼š
```
Epoch    è®­ç»ƒæŸå¤±         éªŒè¯æŸå¤±
--------------------------------------------------------------------------------
1        1.6789          1.5678
2        1.3456          1.2345
3        1.4567          1.3456

ğŸ“Š ç»Ÿè®¡:
  æœ€ä½³Epoch: 2
  æœ€ä½³éªŒè¯æŸå¤±: 1.2345
  æ€»è®­ç»ƒè½®æ•°: 3
```

### æ¸…ç†æ—§æ£€æŸ¥ç‚¹
```bash
# ä¿ç•™æœ€è¿‘3ä¸ª
python train_manager.py clean --keep 3

# ä¿ç•™æœ€è¿‘5ä¸ª
python train_manager.py clean --keep 5
```

### æ¯”è¾ƒæ¨¡å‹
```bash
python train_manager.py compare checkpoints/best_model.pt checkpoints/model_epoch_3.pt
```

## ğŸš€ éƒ¨ç½²ä½¿ç”¨

### ä½¿ç”¨æœ€ä½³æ¨¡å‹
```bash
# å¯åŠ¨æœåŠ¡ï¼ˆè‡ªåŠ¨ä½¿ç”¨best_model.ptï¼‰
LLM_CHECKPOINT=checkpoints/best_model.pt make serve

# æˆ–è€…ç›´æ¥è¿è¡Œ
LLM_CHECKPOINT=checkpoints/best_model.pt python serve.py
```

### æµ‹è¯•ä¸åŒæ£€æŸ¥ç‚¹
```bash
# æµ‹è¯•epoch 2çš„æ¨¡å‹
LLM_CHECKPOINT=checkpoints/model_epoch_2.pt python serve.py

# æµ‹è¯•æœ€æ–°æ¨¡å‹
LLM_CHECKPOINT=checkpoints/latest.pt python serve.py
```

## ğŸ“Š è®­ç»ƒæ—¥å¿—æ ¼å¼

æ¯è½®è®­ç»ƒè¾“å‡ºï¼š
```
======================================================================
ğŸ“š Epoch 1/3
======================================================================
è®­ç»ƒä¸­: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [05:23<00:00, 3.09it/s, loss=1.234, avg_loss=1.456]

ğŸ” éªŒè¯ä¸­...
éªŒè¯: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [00:45<00:00, 5.51it/s]

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“Š Epoch 1/3 ç»“æœ:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â±ï¸  ç”¨æ—¶: 368.5s (6.1min)
  ğŸ“‰ è®­ç»ƒæŸå¤±: 1.4567
  ğŸ“Š éªŒè¯æŸå¤±: 1.2345
  âœ¨ æ–°çš„æœ€ä½³æŸå¤±! (æå‡: 0.3210)
  ğŸ’¾ Epochæ£€æŸ¥ç‚¹: model_epoch_1.pt
  ğŸ† æœ€ä½³æ¨¡å‹: best_model.pt
  ğŸ“Œ æœ€æ–°æ¨¡å‹: latest.pt
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

## ğŸ“ æœ€ä½³å®è·µ

### 1. é•¿æ—¶é—´è®­ç»ƒ
```bash
# ä½¿ç”¨nohupåå°è®­ç»ƒ
nohup python train_chinese.py --epochs 10 --batch-size 4 > training.log 2>&1 &

# æŸ¥çœ‹è®­ç»ƒè¿›åº¦
tail -f training.log
```

### 2. æ„å¤–ä¸­æ–­åæ¢å¤
```bash
# è‡ªåŠ¨ä»latest.ptæ¢å¤
python train_chinese.py --resume --epochs 5
```

### 3. å®šæœŸæ¸…ç†æ£€æŸ¥ç‚¹
```bash
# æ¯æ¬¡è®­ç»ƒåæ¸…ç†ï¼Œä¿ç•™æœ€è¿‘3ä¸ª
python train_manager.py clean --keep 3
```

### 4. æ€§èƒ½ç›‘æ§
```bash
# è®­ç»ƒæ—¶ç›‘æ§GPU
watch -n 1 nvidia-smi

# æŸ¥çœ‹è®­ç»ƒå†å²è¶‹åŠ¿
python train_manager.py history
```

## ğŸ”¥ å¿«é€Ÿå¼€å§‹

```bash
# 1. ä¸‹è½½æ•°æ®
python download_chinese_data.py --type sample

# 2. å¼€å§‹è®­ç»ƒï¼ˆ3è½®ï¼Œä¿ç•™æœ€è¿‘3ä¸ªæ£€æŸ¥ç‚¹ï¼‰
python train_chinese.py \
  --data-file data/zh_sample.txt \
  --epochs 3 \
  --batch-size 4 \
  --keep-last-n 3

# 3. æŸ¥çœ‹ç»“æœ
python train_manager.py list
python train_manager.py history

# 4. ä½¿ç”¨æœ€ä½³æ¨¡å‹
LLM_CHECKPOINT=checkpoints/best_model.pt make serve
```

## ğŸ“ˆ è®­ç»ƒå†å²JSONæ ¼å¼

`checkpoints/training_history.json`:
```json
{
  "train_loss": [1.6789, 1.3456, 1.4567],
  "val_loss": [1.5678, 1.2345, 1.3456],
  "epochs": [1, 2, 3]
}
```

## ğŸ› ï¸ æ•…éšœæ’æŸ¥

### é—®é¢˜1ï¼šGPUå†…å­˜ä¸è¶³
```bash
# å‡å°‘batch size
python train_chinese.py --batch-size 2

# æ£€æŸ¥GPUçŠ¶æ€
nvidia-smi
```

### é—®é¢˜2ï¼šæ£€æŸ¥ç‚¹æŸå
```bash
# ä½¿ç”¨å‰ä¸€ä¸ªepochçš„æ£€æŸ¥ç‚¹
python train_chinese.py --checkpoint checkpoints/model_epoch_2.pt --epochs 5
```

### é—®é¢˜3ï¼šè®­ç»ƒä¸­æ–­
```bash
# å§‹ç»ˆå¯ä»¥ä»latest.ptæ¢å¤
python train_chinese.py --resume --epochs 5
```
