#!/usr/bin/env python3
"""è®­ç»ƒç®¡ç†å·¥å…· - æŸ¥çœ‹æ£€æŸ¥ç‚¹ã€æ¢å¤è®­ç»ƒã€åˆ†æå†å²"""
import json
import pickle
from pathlib import Path
from datetime import datetime
import argparse


def load_checkpoint(path):
    """åŠ è½½æ£€æŸ¥ç‚¹ï¼ˆä»…æ”¯æŒ pickle æ ¼å¼ï¼‰"""
    try:
        with open(path, 'rb') as f:
            return pickle.load(f)
    except Exception as e:
        raise RuntimeError(f"æ— æ³•åŠ è½½æ£€æŸ¥ç‚¹ {path}: {e}\\næç¤º: æ–°ç‰ˆæœ¬ä»…æ”¯æŒ pickle æ ¼å¼(.pkl)")


def list_checkpoints(checkpoint_dir="checkpoints"):
    """åˆ—å‡ºæ‰€æœ‰æ£€æŸ¥ç‚¹"""
    checkpoint_dir = Path(checkpoint_dir)
    
    print("=" * 80)
    print("ğŸ“¦ æ£€æŸ¥ç‚¹åˆ—è¡¨")
    print("=" * 80)
    
    checkpoints = []
    
    # æœ€ä½³æ¨¡å‹
    best = checkpoint_dir / "best_model.pt"
    if best.exists():
        stat = best.stat()
        size_mb = stat.st_size / (1024 * 1024)
        mtime = datetime.fromtimestamp(stat.st_mtime)
        
        try:
            ckpt = load_checkpoint(best)
            val_loss = ckpt.get('val_loss', ckpt.get('best_loss', 'N/A'))
            epoch = ckpt.get('epoch', 'N/A')
            checkpoints.append({
                'name': 'ğŸ† best_model.pt',
                'epoch': epoch,
                'val_loss': val_loss,
                'size': size_mb,
                'time': mtime
            })
        except:
            pass
    
    # æœ€æ–°æ¨¡å‹
    latest = checkpoint_dir / "latest.pt"
    if latest.exists():
        stat = latest.stat()
        size_mb = stat.st_size / (1024 * 1024)
        mtime = datetime.fromtimestamp(stat.st_mtime)
        
        try:
            ckpt = load_checkpoint(latest)
            val_loss = ckpt.get('val_loss', 'N/A')
            epoch = ckpt.get('epoch', 'N/A')
            checkpoints.append({
                'name': 'ğŸ“Œ latest.pt',
                'epoch': epoch,
                'val_loss': val_loss,
                'size': size_mb,
                'time': mtime
            })
        except:
            pass
    
    # Epochæ£€æŸ¥ç‚¹
    for ckpt_file in sorted(checkpoint_dir.glob("model_epoch_*.pt")):
        stat = ckpt_file.stat()
        size_mb = stat.st_size / (1024 * 1024)
        mtime = datetime.fromtimestamp(stat.st_mtime)
        
        try:
            ckpt = load_checkpoint(ckpt_file)
            val_loss = ckpt.get('val_loss', 'N/A')
            epoch = ckpt.get('epoch', 'N/A')
            checkpoints.append({
                'name': f'ğŸ“¦ {ckpt_file.name}',
                'epoch': epoch,
                'val_loss': val_loss,
                'size': size_mb,
                'time': mtime
            })
        except:
            pass
    
    # æ‰“å°è¡¨æ ¼
    if checkpoints:
        print(f"{'æ–‡ä»¶':<30} {'Epoch':<8} {'éªŒè¯æŸå¤±':<12} {'å¤§å°(MB)':<10} {'ä¿®æ”¹æ—¶é—´':<20}")
        print("-" * 80)
        for ckpt in checkpoints:
            epoch_str = str(ckpt['epoch']) if ckpt['epoch'] != 'N/A' else 'N/A'
            loss_str = f"{ckpt['val_loss']:.4f}" if isinstance(ckpt['val_loss'], float) else str(ckpt['val_loss'])
            print(f"{ckpt['name']:<30} {epoch_str:<8} {loss_str:<12} {ckpt['size']:<10.2f} {ckpt['time'].strftime('%Y-%m-%d %H:%M:%S')}")
    else:
        print("æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹")
    
    print("=" * 80)


def show_history(checkpoint_dir="checkpoints"):
    """æ˜¾ç¤ºè®­ç»ƒå†å²"""
    history_file = Path(checkpoint_dir) / "training_history.json"
    
    if not history_file.exists():
        print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå†å²æ–‡ä»¶")
        return
    
    with open(history_file) as f:
        history = json.load(f)
    
    print("\n" + "=" * 80)
    print("ğŸ“ˆ è®­ç»ƒå†å²")
    print("=" * 80)
    print(f"{'Epoch':<8} {'è®­ç»ƒæŸå¤±':<15} {'éªŒè¯æŸå¤±':<15}")
    print("-" * 80)
    
    for i, epoch in enumerate(history['epochs']):
        train_loss = history['train_loss'][i]
        val_loss = history['val_loss'][i]
        print(f"{epoch:<8} {train_loss:<15.4f} {val_loss:<15.4f}")
    
    print("=" * 80)
    
    # ç»Ÿè®¡ä¿¡æ¯
    if history['val_loss']:
        best_epoch = history['epochs'][history['val_loss'].index(min(history['val_loss']))]
        best_loss = min(history['val_loss'])
        print(f"\nğŸ“Š ç»Ÿè®¡:")
        print(f"  æœ€ä½³Epoch: {best_epoch}")
        print(f"  æœ€ä½³éªŒè¯æŸå¤±: {best_loss:.4f}")
        print(f"  æ€»è®­ç»ƒè½®æ•°: {len(history['epochs'])}")


def compare_checkpoints(ckpt1, ckpt2):
    """æ¯”è¾ƒä¸¤ä¸ªæ£€æŸ¥ç‚¹"""
    print(f"\nğŸ” æ¯”è¾ƒæ£€æŸ¥ç‚¹:")
    print(f"  æ¨¡å‹1: {ckpt1}")
    print(f"  æ¨¡å‹2: {ckpt2}")
    print("-" * 80)
    
    try:
        c1 = load_checkpoint(ckpt1)
        c2 = load_checkpoint(ckpt2)
        
        print(f"{'æŒ‡æ ‡':<20} {'æ¨¡å‹1':<20} {'æ¨¡å‹2':<20}")
        print("-" * 60)
        print(f"{'Epoch':<20} {c1.get('epoch', 'N/A'):<20} {c2.get('epoch', 'N/A'):<20}")
        print(f"{'è®­ç»ƒæŸå¤±':<20} {c1.get('train_loss', 'N/A'):<20} {c2.get('train_loss', 'N/A'):<20}")
        print(f"{'éªŒè¯æŸå¤±':<20} {c1.get('val_loss', 'N/A'):<20} {c2.get('val_loss', 'N/A'):<20}")
        print(f"{'æœ€ä½³æŸå¤±':<20} {c1.get('best_loss', 'N/A'):<20} {c2.get('best_loss', 'N/A'):<20}")
        
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")


def clean_old_checkpoints(checkpoint_dir="checkpoints", keep_n=3):
    """æ¸…ç†æ—§çš„epochæ£€æŸ¥ç‚¹"""
    checkpoint_dir = Path(checkpoint_dir)
    epoch_files = sorted(checkpoint_dir.glob("model_epoch_*.pt"))
    
    if len(epoch_files) <= keep_n:
        print(f"âœ“ å½“å‰æœ‰ {len(epoch_files)} ä¸ªæ£€æŸ¥ç‚¹ï¼Œæ— éœ€æ¸…ç†")
        return
    
    print(f"ğŸ—‘ï¸  æ¸…ç†æ—§æ£€æŸ¥ç‚¹ (ä¿ç•™æœ€è¿‘ {keep_n} ä¸ª)...")
    for old_file in epoch_files[:-keep_n]:
        size_mb = old_file.stat().st_size / (1024 * 1024)
        print(f"  åˆ é™¤: {old_file.name} ({size_mb:.2f} MB)")
        old_file.unlink()
    
    print(f"âœ“ æ¸…ç†å®Œæˆï¼Œå‰©ä½™ {keep_n} ä¸ªæ£€æŸ¥ç‚¹")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="è®­ç»ƒç®¡ç†å·¥å…·")
    parser.add_argument("--checkpoint-dir", default="checkpoints", help="æ£€æŸ¥ç‚¹ç›®å½•")
    
    subparsers = parser.add_subparsers(dest="command", help="å­å‘½ä»¤")
    
    # listå‘½ä»¤
    list_parser = subparsers.add_parser("list", help="åˆ—å‡ºæ‰€æœ‰æ£€æŸ¥ç‚¹")
    
    # historyå‘½ä»¤
    history_parser = subparsers.add_parser("history", help="æ˜¾ç¤ºè®­ç»ƒå†å²")
    
    # compareå‘½ä»¤
    compare_parser = subparsers.add_parser("compare", help="æ¯”è¾ƒä¸¤ä¸ªæ£€æŸ¥ç‚¹")
    compare_parser.add_argument("ckpt1", help="ç¬¬ä¸€ä¸ªæ£€æŸ¥ç‚¹")
    compare_parser.add_argument("ckpt2", help="ç¬¬äºŒä¸ªæ£€æŸ¥ç‚¹")
    
    # cleanå‘½ä»¤
    clean_parser = subparsers.add_parser("clean", help="æ¸…ç†æ—§æ£€æŸ¥ç‚¹")
    clean_parser.add_argument("--keep", type=int, default=3, help="ä¿ç•™æœ€è¿‘Nä¸ª")
    
    args = parser.parse_args()
    
    if args.command == "list":
        list_checkpoints(args.checkpoint_dir)
    elif args.command == "history":
        show_history(args.checkpoint_dir)
    elif args.command == "compare":
        compare_checkpoints(args.ckpt1, args.ckpt2)
    elif args.command == "clean":
        clean_old_checkpoints(args.checkpoint_dir, args.keep)
    else:
        parser.print_help()
