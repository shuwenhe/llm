"""core å¿«é€Ÿæ–‡æœ¬ç”Ÿæˆæµ‹è¯•å®ç°"""

import os
import pickle

import numpy as np

from app.core.models import TinyLM
from app.core.tokenizer import CharTokenizer


def quick_test():
    checkpoint_path = os.getenv("LLM_CHECKPOINT", "checkpoints/model_core.pkl")

    if not os.path.exists(checkpoint_path):
        print(f"âŒ æ¨¡å‹æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}\n")
        print("è¯·å…ˆè®­ç»ƒæ¨¡å‹:")
        print("  make train-core")
        print("  make train-chinese")
        return

    print("ğŸš€ å¿«é€Ÿç”Ÿæˆæµ‹è¯•")
    print("åç«¯: core")
    print("=" * 60)

    with open(checkpoint_path, "rb") as f:
        payload = pickle.load(f)
    tokenizer = CharTokenizer.from_dict(payload["tokenizer"])
    model = TinyLM(vocab_size=payload["model"]["vocab_size"], n_embd=payload["model"]["n_embd"])
    for i, p in enumerate(model.parameters()):
        p.data[...] = payload["model"]["state_dict"][f"param_{i}"]

    test_prompts = [
        "Once upon a time",
        "The meaning of life is",
        "In a world where",
    ]

    test_configs = [
        {"name": "ä¿å®ˆæ¨¡å¼", "temp": 0.7, "tokens": 80},
        {"name": "å¹³è¡¡æ¨¡å¼", "temp": 0.8, "tokens": 120},
        {"name": "åˆ›æ„æ¨¡å¼", "temp": 1.0, "tokens": 150},
    ]

    for prompt in test_prompts:
        print(f"\n{'='*60}")
        print(f"ğŸ“ æç¤ºè¯: \"{prompt}\"")
        print(f"{'='*60}")

        for cfg in test_configs:
            print(f"\nğŸ”§ {cfg['name']} (temp={cfg['temp']}, tokens={cfg['tokens']})")
            print("-" * 60)

            ids = tokenizer.encode(prompt)
            if not ids:
                ids = [0]

            for _ in range(cfg["tokens"]):
                x = np.array([ids], dtype=np.int64)
                logits, _ = model(x, None)
                next_logits = logits.data[0, -1] / max(cfg["temp"], 1e-6)
                next_logits = next_logits - np.max(next_logits)
                probs = np.exp(next_logits)
                probs = probs / (probs.sum() + 1e-12)
                next_id = int(np.random.choice(len(probs), p=probs))
                ids.append(next_id)

            generated_text = tokenizer.decode(ids)
            print(generated_text)

    print("\n" + "=" * 60)
    print("âœ… æµ‹è¯•å®Œæˆï¼é€‰æ‹©æ•ˆæœæœ€å¥½çš„å‚æ•°åœ¨ generate.py ä¸­ä½¿ç”¨")


if __name__ == "__main__":
    quick_test()
